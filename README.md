# Notes on AI papers/blogs/courses

Collection of simple TLDRs, key points and novelties from read papers. These are
just for personal reference, they'll likely contain errors, missing information,
etc.

Each paper has:
- Summary
- Key Points
- Notes/Questions
- Tags (datasets used, methods, etc.)

Inspired by [dennybritz' repo](https://github.com/dennybritz/deeplearning-papernotes)

## Papers

### 2017

- [Dynamic Routing Between Capsules](notes/capsule_networks.md)
- [Maximizing Subset Accuracy with Recurrent Neural Networks in Multi-label Classification](notes/maximizing_acc_rnn_mlc.md)
- [A Structured Self-attentive Sentence Embedding](notes/self_attentive_sentence_embedding.md)
- [MinimalRNN: Towards More Interpretable and Trainable Recurrent Neural Networks](notes/minimalrnn.md)
- [Attention is All You Need](notes/all_attention.md)
- [Deep Sets](notes/deep_sets.md)
- [Topically Driven Neural Language Model](notes/topical_neural_language_model.md)

### 2016

- [Neural Architectures for Named Entity Recognition](notes/neural_ner.md)

### 2015

- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](notes/batch_normalization.md)

### 2010

- [A Literature Survey on Algorithms for Multi-label Learning](notes/legacy_survey_mlc.md)
